---
title: "First Steps"
author: "Martin Binder"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{1. First Steps}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, eval = TRUE, child = 'toc/vignettetoc.Rmd'}
```

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

## About the Vignettes

Since `mlrCPO` is a package with some depth to it, it comes with a few vignettes that each explain different aspects of its operation. These are the current document ("First Steps"), offering a short introduction and information on where to get started, "[mlrCPO Core](a_2_mlrCPO_core.html)", describing all the functions and tools offered by `mlrCPO` that are independent from specific `CPO`s, "[CPOs Built Into mlrCPO](a_3_all_CPOs.html)", listing all `CPO`s included in the `mlrCPO` package, and "[Building Custom CPOs](a_4_custom_CPOs.html)", describing the process of creating new `CPO`s that offer new functionality.

All vignettes also have a "compact version" with the R output suppressed for readability. They are linked in the navigation section at the top.

All vignettes assume that `mlrCPO` (and therefore its requirement `mlr`) is installed successfully and loaded using `library("mlrCPO")`. Help with installation is provided on the [project's GitHub page](https://github.com/mlr-org/mlrCPO).

## What is mlrCPO?

"Composable Preprocessing Operators", "CPO", are an extension for the [mlr](https://github.com/mlr-org/mlr) ("Machine Learning in R") project which present preprocessing operations in the form of R objects. These CPO objects can be composed to form complex operations, they can be applied to data sets, and can be attached to mlr `Learner` objects to generate machine learning pipelines that combine preprocessing and model fitting.

### What is Preprocessing

"Preprocessing", as understood by `mlrCPO`, is any manipulation of data used in a machine learning process to get it from its form as found in the wild into a form more fitting for the machine learning algorithm ("`Learner`") used for model fitting. It is important that the exact method of preprocessing is kept track of, to be able to perform this method when the resulting model is used to make predictions on new data. It is also important, when evaluating preprocessing methods e.g. using *resampling*, that the parameters of these methods are independent of the validation dataset and only depend on the training data set.

`mlrCPO` tries to support the user in all these aspects of preprocessing:

1. By providing a large set of atomic preprocessing `CPO`s that can perform many different operations. Operations that go beyond the provided toolset can be implemented in custom `CPO`s.
2. By using "`CPOTrained`" objects that represent the preprocessing done on training data that should, in that way, be re-applied to new prediction data.
3. By making it possible to combine preprocessing objects with `mlr` "`Learner`" objects that represent the entinre machine learning pipeline to be tuned and evaluated.

## Preprocessing Operations

At the centre of `mlrCPO` are "`CPO`" objects. To get a `CPO` object, it is necessary to call a
*CPO Constructor*. A CPO Constructor sets up the parameters of a `CPO` and provides further
options for its behaviour. Internally, CPO Constructors are *functions* that have a common
interface and a friendly printer method.
```{r}
cpoScale  # a cpo constructor
cpoAddCols

cpoScale(center = FALSE)  # create a CPO object that scales, but does not center, data
cpoAddCols(Sepal.Area = Sepal.Length * Sepal.Width)  #  this would add a column
```

`CPO`s exist first to be *applied* to data. Every `CPO` represents a certain data transformation,
and this transformation is performed when the `CPO` is applied. This can be done using the
**`applyCPO`** function, or the **`%>>%`** operator. `CPO`s can be applied to `data.frame` objects,
and to `mlr` "`Task`" objects.
```{r}
iris.demo = iris[c(1, 2, 3, 51, 52, 102, 103), ]
tail(iris.demo %>>% cpoQuantileBinNumerics())  # bin the data in below & above median
```

A useful feature of `CPO`s is that they can be concatenated t form new operations. Two `CPO`s
can be combines using the **`composeCPO`** function or, as before, the **`%>>%`** operator.
When two `CPO`s are combined, the product is a new `CPO` that can itself be composed or applied.
When two `CPO`s are composed, the result represents the operation of first applying the first, then
the second `CPO`. Therefore, `data %>>% (cpo1 %>>% cpo2)` is the same as `(data %>>% cpo1) %>>% cpo2`.
```{r}
# first create three quantile bins, then as.numeric() all columns to
# get 1, 2 or 3 as the bin number
quantilenum = cpoQuantileBinNumerics(numsplits = 3) %>>% cpoAsNumeric()
iris.demo %>>% quantilenum
```

The last example shows that it is sometimes not a good idea to have a `CPO` affect the whole
dataset. Therefore, when a `CPO` is created, it is possible to choose what columns the `CPO`
should affect. The CPO Constructor has a variety of parameters, starting with `affect.`,
that can be used to choose what columns the `CPO` operates on. To prevent `cpoAsNumeric`
from influencing the `Species` column, we can thus do
```{r}
quantilenum.restricted = cpoQuantileBinNumerics(numsplits = 3) %>>%
  cpoAsNumeric(affect.names = "Species", affect.invert = TRUE)
iris.demo %>>% quantilenum.restricted
```

A more convenient method in this case, however, is to use an `mlr` "`Task`", which keeps track of
the target column. "Feature Operation" `CPO`s (as all the ones shown) do not influence the target
column.
```{r}
demo.task = makeClassifTask(data = iris.demo, target = "Species")
result = demo.task %>>% quantilenum
getTaskData(result)
```

## Hyperparameters

When performing preprocessing, it is sometimes necessary to change a small aspect of a long
preprocessing pipeline. Instead of having to re-construct the whole pipeline, `mlrCPO` offers
the possibility to change *hyperparameters* of a `CPO`. This makes it very easy e.g. for tuning
of preprocessing in combination with a machine learning algorithm.

Hyperparameters of `CPO`s can be manipulated in the same way as they are manipulated for `Learners`
in `mlr`, using **`getParamSet`** (to list the parameters), **`getHyperPars`** (to list the parameter values),
and **`setHyperPars`** (to change these values). To get the parameter set of a `CPO`, it is also possible to
use **verbose printing** using the `!` (exclamation mark) operator.
```{r}
cpo = cpoScale()
cpo
getHyperPars(cpo)  # list of parameter names and values
getParamSet(cpo)  # more detailed view of parameters and their type / range
!cpo  # equivalent to print(cpo, verbose = TRUE)
```

`CPO`s use copy semantics, therefore `setHyperPars` creates a copy of a `CPO` that has the changed hyperparameters.
```{r}
cpo2 = setHyperPars(cpo, scale.scale = FALSE)
cpo2
iris.demo %>>% cpo  # scales and centers
iris.demo %>>% cpo2 # only centers
```

When chaining many `CPO`s, it is possible for the many hyperparameters to lead to very cluttered `ParamSet`s,
or even for hyperparameter names to clash. `mlrCPO` has two remedies for that.

First, any `CPO` also has an **`id`** that is always prepended to the hyperparameter names. It can be set
during construction, using the `id` parameter, or changed later using `setCPOId`. The latter one only works
on primitive, i.e. not compound, `CPO`s. Set the `id` to `NULL` to use the `CPO`'s hyperparameters without a prefix.

```{r}
cpo = cpoScale(id = "a") %>>% cpoScale(id = "b")  # not very useful example
getHyperPars(cpo)
```

The second remedy against hyperparameter clashes is different "exports" of hyperparameters:
The hyperparameters that can be changed using `setHyperPars`, i.e. that are *exported* by a `CPO`,
are a subset of the parameters of the `CPOConstructor`.
For each kind of `CPO`, there is a standard set of parameters that are exported, but during construction,
it is possible to influence the parameters that actually get exported via the `export` parameter.
`export` can be one of a set of standard export settings (among them "`export.all`" and "`export.none`") or
a `character` vector of the parameters to export.

```{r}
cpo = cpoPca(export = c("center", "rank"))
getParamSet(cpo)
```

## Retrafo

Manipulating data for preprocessing itself is relatively easy. A challenge comes when one wants to integrate preprocessing
into a machine-learning pipeline: The same preprocessing steps that are performed on the training data need to be performed
on the new prediction data. However, the transformation performed for prediction often needs information from the training step.
For example, if training entail performing PCA, then for prediction, the data must not undergo another PCA, instead it needs
to be rotated by the *rotation matrix* found by the training PCA. The process of obtaining the rotation matrix will be called
"training" the `CPO`, and the object that contains the trained information is called `CPOTrained`. For preprocessing operations
that operate only on *features* of a task (as opposed to the target column), the `CPOTrained` will always be applied to new
incoming data, and hence be of class `CPORetrafo` and called a "**retrafo**" object. To obtain this retrafo object, one can use
**`retrafo()`**. Retrafo objects can be applied to data just as `CPO`s can, by using the `%>>%` operator.
```{r}
transformed = iris.demo %>>% cpoPca(rank = 3)
transformed

ret = retrafo(transformed)
ret
```

To show that `ret` actually represents the exact same preprocessing operation, we can feed the first line of `iris.demo` back to
it, to verify that the transformation is the same.
```{r}
iris.demo[1, ] %>>% ret
```

Obviously we would not have gotten there by feeding the first line to `cpoPca` directly:
```{r}
iris.demo[1, ] %>>% cpoPca(rank = 3)
```

## Inverter

So far only `CPO`s were introduced that change the feature columns of a `Task`. ("Feature Operation `CPO`s"--*FOCPO*s). There is another class of `CPO`s, "Target Operation `CPO`s" or *TOCPO*s, that can change a `Task`'s target columns.

This comes at the cost of some complexity when performing prediction: Since the training data that was ultimately fed into a `Learner` had a transformed target column, the predictions made by the resulting model will not be directly comparable to the original target values. Consider `cpoLogTrafoRegr`, a `CPO` that log-transforms the target variable of a regression `Task`. The predictions made with a `Learner` on a log-transformed target variable will be in log-space and need to be exponentiated (or otherwise re-transformed). This inversion operation is represented by an "**inverter**" object that is attached to a transformation result similarly to a retrafo object, and can be obtained using the **`inverter()`** function. It is of class `CPOInverter`, a subclass of `CPOTrained`.

```{r}
iris.regr = makeRegrTask(data = iris.demo, target = "Petal.Width")
iris.logd = iris.regr %>>% cpoLogTrafoRegr()

getTaskData(iris.logd)  # log-transformed target 'Petal.Width'

inv = inverter(iris.logd)  # inverter object
inv
```

The inverter object is used by the `invert()` function that inverts the prediction made by a model trained on the transformed task, and re-transforms this prediction to fit the space of the original target data. The inverter object caches the "truth" of the data being inverted (`iris.logd`, in the example), so `invert` can give information on the truth of the inverted data.
```{r}
logmodel = train("regr.lm", iris.logd)
pred = predict(logmodel, iris.logd)  # prediction on the task itself
pred

invert(inv, pred)
```

This procedure can also be done with new incoming data. In general, more than just the `cpoLogTrafoRegr` operation could be done on the `iris.regr` task in the example, so to perform the complete preprocessing *and* inversion, one needs to use the retrafo object as well. When applying the retrafo object, a new inverter object is generated, which is specific to the exact new data that was being retransformed:
```{r}
newdata = makeRegrTask("newiris", iris[7:9, ], target = "Petal.Width")

# the retrafo does the same transformation(s) on newdata that were
# done on the training data of the model, iris.logd. In general, this
# could be more than just the target log transformation.
newdata.transformed = newdata %>>% retrafo(iris.logd)
getTaskData(newdata.transformed)

pred = predict(logmodel, newdata.transformed)
pred

# the inverter of the newly transformed data contains information specific
# to the newly transformed data. In the current case, that is just the
# new "truth" column for the new data.
inv.newdata = inverter(newdata.transformed)
invert(inv.newdata, pred)
```

### Constant Inverters

The `cpoLogTrafoRegr` is a special case of TOCPO in that its inversion operation is *constant*: It does not depend on the new incoming data, so in theory it is not necessary to get a new inverter object for every piece of data that is being transformed. Therefore, it is possible to use the *retrafo* object for inversion in this case. However, the "truth" column will not be available in this case:

```{r}
invert(retrafo(iris.logd), pred)
```

Whether a retrafo object is capable of performing inversion can be checked with the **`getCPOTrainedCapability()`** function. It returns a vector with named elements `"retrafo"` and `"invert"`, indicating whether a `CPOTrained` is capable of performing retrafo or inversion. A `1` indicates that the object can perform the action and has an effect, a `0` indicates that the action would have no effect (but also throws no error), and a `-1` means that the object is not capable of performing the action.
```{r}
getCPOTrainedCapability(retrafo(iris.logd))  # can do both retrafo and inversion
getCPOTrainedCapability(inv)  # a pure inverter, can not be used for retrafo
```




## THE REST

When attaching a `CPO` to a `Learner` using the `%>>%`-operator, all this is performed by `mlrCPO`, so there is no need to
worry about keeping `CPOTrained` objects around.

`retrafo()` gets the retrafo object from an attribute of the `transformed` object. The retrafo is always generated by the application
of a `CPO` already. Retrafos that are attached to an object also stack, so multiple applications of different `CPO`s only need
one `retrafo()` call to get the respective retrafo operation.
```{r}
trans.a = iris %>>% cpoScale()
trans.b = trans.a %>>% cpoPca()
ret = retrafo(trans.b)
```
Check that 'ret' does what it is supposed to do:
```{r}
head(trans.b)
head(iris) %>>% ret
```

### Tuning
Since the hyperparameters remain intact for learners, is possible to tune hyperparameters parameters of preprocessing operations.

```{r}
(clrn = cpoModelMatrix() %>>% makeLearner("classif.logreg"))
```
```{r}
getParamSet(clrn)
```
```{r, echo = FALSE}
set.seed(123)
```
```{r}
ps = makeParamSet(
    makeDiscreteParam(
        "model.matrix.formula",
        values = list(first = ~0 + ., second = ~0 + .^2, third = ~0 + .^3)))

tuneParams(clrn, pid.task, cv5, par.set = ps,
           control = makeTuneControlGrid(),
           show.info = TRUE)
```

## Special CPOs

### CPO Multiplexer
The multiplexer makes it possible to combine many CPOs into one, with an extra `selected.cpo` parameter that chooses between them.

```{r}
cpm = cpoMultiplex(list(cpoScale, cpoPca))
print(cpm, verbose = TRUE)
```
```{r}
head(iris %>>% setHyperPars(cpm, selected.cpo = "scale"))
```
Every CPO's Hyperparameters are exported:
```{r}
head(iris %>>% setHyperPars(cpm, selected.cpo = "scale", scale.center = FALSE))
```
```{r}
head(iris %>>% setHyperPars(cpm, selected.cpo = "pca"))
```

This makes it possible to tune over many different tuner configurations at once.

### CPO Wrapper
A simple CPO with one parameter which gets applied to the data as CPO. This is different from a multiplexer in that its parameter is free and can take any value that behaves like a CPO. On the downside, this does not expose the argument's parameters to the outside.

```{r}
cpa = cpoWrap()
print(cpa, verbose = TRUE)
```
```{r}
head(iris %>>% setHyperPars(cpa, wrap.cpo = cpoScale()))
```
```{r}
head(iris %>>% setHyperPars(cpa, wrap.cpo = cpoPca()))
```
Attaching the cpo applicator to a learner gives this learner a "cpo" hyperparameter that can be set to any CPO.
```{r}
getParamSet(cpoWrap() %>>% makeLearner("classif.logreg"))
```

### CBind CPO
`cbind` other CPOs as operation. The `cbinder` makes it possible to build DAGs of CPOs that perform different operations on data and paste the results next to each other.

```{r}
scale = cpoScale(id = "scale")
scale.pca = scale %>>% cpoPca()
cbinder = cpoCbind(scaled = scale, pcad = scale.pca, original = NULLCPO)
```
`cpoCbind` recognises that `"scale.scale"` happens before `"pca.pca"` but is also fed to the result directly. The summary draws a (crude) ascii-art graph.
```{r}
print(cbinder)
```
```{r}
getParamSet(cbinder)
```
```{r}
head(iris %>>% cbinder)
```
The unnecessary copies of "Species" are unfortunate. Remove them with cpoSelect:
```{r}
selector = cpoSelect(type = "numeric")
cbinder.select = cpoCbind(scaled = selector %>>% scale, pcad = selector %>>% scale.pca, original = NULLCPO)
cbinder.select
head(iris %>>% cbinder)
```
alternatively, we apply the cbinder only to numerical data
```{r}
head(iris %>>% cpoWrap(cbinder, affect.type = "numeric"))
```

## Custom CPOs

Even though `CPO`s are very flexible and can be combined in many ways, it may be necessary to create completely custom `CPO`s.
Custom CPOs can be created using the `makeCPO` function. Its most important arguments are `cpo.trafo` and `cpo.retrafo`, both of which are functions.
In principle, a `CPO` needs a function that "trains" a control object depending on the data (`cpo.trafo`),
and another function that uses this control object, and new data, to perform the preprocessing operation (`cpo.retrafo`).
The `cpo.trafo`-function must return a "control" object which contains all information about how to transform a given dataset.
`cpo.retrafo` takes a (potentially new!) dataset *and* the "control" object returned by `cpo.trafo`, and transforms the new data according to plan.
```{r}
names(formals(makeCPO))  # see help(makeCPO) for explanation of arguments
```

```{r}
constFeatRem = makeCPO("constFeatRem",  # nolint
  dataformat = "df.features",
  cpo.train = function(data, target) {
    names(Filter(function(x) {  # names of columns to keep
        length(unique(x)) > 1
      }, data))
    }, cpo.retrafo = function(data, control) {
    data[control]
  })
head(iris) %>>% constFeatRem()
print(constFeatRem, verbose = TRUE)
```



## Tuning CPO
CPOs export their parameters when attached to a learner. Tuning of CPO-Learners works exactly as tuning for ordinary Learners.

```{r}
(clrn = cpoModelMatrix() %>>% makeLearner("classif.logreg"))
getParamSet(clrn)

ps = makeParamSet(
    makeDiscreteParam(
        "model.matrix.formula",
        values = list(first = ~0 + ., second = ~0 + .^2, third = ~0 + .^3)))

tuneParams(clrn, pid.task, cv5, par.set = ps,
           control = makeTuneControlGrid(),
           show.info = TRUE)
```
Tuning of CPOs and tuning of Learners can happen at the same time. The following is not executed to save build time.
```{r, eval = FALSE}
tlrn = cpoModelMatrix() %>>%
       cpoWrap() %>>%
       cpoFilterGainRatio() %>>%
       makeLearner("classif.ctree")
sprintf("Parameters: %s", paste(names(getParamSet(tlrn)$pars), collapse=", "))
ps2 = makeParamSet(
    makeDiscreteParam(
        "model.matrix.formula",
        values = list(first = ~0 + ., second = ~0 + .^2)),
    makeDiscreteParam(
        "wrap.cpo",
        values = list(nopca = NULLCPO,
                      onlypca = cpoPca(),
                      addpca = cpoCbind(NULLCPO, cpoPca()))),
    makeDiscreteParam(
        "gain.ratio.perc",
        values = list(0.333, 0.667, 1.0)),
    makeDiscreteParam("teststat", values = c("quad", "max")))

tuneParams(tlrn, pid.task, cv5, par.set = ps2,
           control = makeTuneControlGrid())
```
