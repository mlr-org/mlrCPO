---
title: "mlrCPO: Composable Preprocessing Operators for mlr"
author: "Martin Binder"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mlrCPO}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

This vignette will give an overview over all the different features integrated in `mlrCPO`. To get more information, also use the `R` help pages and the [mlr tutorial page](TODO).

## CPO

**CPO**s are first-class objects in R that represent data manipulation. They can be combined to form networks of operation, they can be attached to `mlr` `Learner`s, and they have tunable Hyperparameters that influence their behaviour.

### Preparation

```{r}
library("mlrCPO")
df = data.frame(a = 1:3, b = -(1:3) * 10)
```

## Lifecycle of a CPO

### CPO Constructor

```{r}
print(cpoPca)  # example CPOConstructor
class(cpoPca)
```

CPO constructors have parameters that

* set the CPO Hyperparameters
* set the CPO ID (default NULL)
* resetrict the data columns a CPO operates on (`affect.*` parameters)

```{r}
names(formals(cpoPca))
print(cpoPca, verbose = TRUE)  # verbose print includes function info
```

### CPO

```{r}
(cpo = cpoScale()) # construct CPO with default Hyperparameter values
class(cpo)  # CPOs that are not compound are "CPOPrimitive"
getCPOClass(cpo)  # CPO Class: CPO, CPOInverter, CPORetrafo, NULLCPO
getCPOOperatingType(cpo)  # Operating on feature, target, both?
print(cpo, verbose = TRUE)  # detailed printing
```

#### Functions that work on CPOs:
```{r}
getParamSet(cpo)
getHyperPars(cpo)
setHyperPars(cpo, scale.center = FALSE)
getCPOId(cpo)
setCPOId(cpo, "MYID")
getCPOName(cpo)
getCPOAffect(cpo)  # empty, since no affect set
getCPOAffect(cpoPca(affect.pattern = "Width$"))
getCPOProperties(cpo)  # see properties explanation below
getCPOPredictType(cpo)
getCPOConstructor(cpo)  # the constructor used to create the CPO
```

#### Exporting Parameters

Sometimes when using many CPOs, their hyperparameters may get messy. CPO enables the user to control which hyperparameter get exported. The parameter "export" can be one of "export.default", "export.set", "export.unset", "export.default.set", "export.default.unset", "export.all", "export.none". "all" and "none" do what one expects; "default" exports the "recommended" parameters; "set" and "unset" export the values that have not been set, or only the values that were set (and are not left as default). "default.set" and "default.unset" work as "set" and "unset", but restricted to the default exported parameters.

```{r}
(sc = cpoScale())
getParamSet(sc)
```
```{r}
(sc = cpoScale(export = "export.none"))
getParamSet(sc)
```
```{r}
(sc = cpoScale(scale = FALSE, export = "export.unset"))
getParamSet(sc)
```

#### CPO Application using `%>>%` or `applyCPO`
`CPO`s can be applied to `data.frame` and `Task` objects.

```{r}
head(iris) %>>% cpoPca()
head(getTaskData(applyCPO(cpoPca(), iris.task)))
```

#### CPO Composition using `%>>%` or `composeCPO`
`CPO` composition results in a new CPO which mostly behaves like a primitive CPO. Exceptions are:

* Compound CPOs have no `id`
* Affect of compound CPOs cannot be retrieved

```{r}
scale1 = cpoScale()
scale2 = cpoScale()
```
```{r, error = TRUE}
scale1 %>>% scale2  # error! parameters 'center' and 'scale' occur in both
```
```{r}
compound = setCPOId(scale1, "scale1") %>>% setCPOId(scale2, "scale2")
composeCPO(setCPOId(scale1, "scale1"), setCPOId(scale2, "scale2"))  # same
class(compound)
print(compound, verbose = TRUE)
getCPOName(compound)
getParamSet(compound)
getHyperPars(compound)
setHyperPars(compound, scale1.center = TRUE, scale2.center = FALSE)
```
```{r, error = TRUE}
getCPOId(compound)  # error: no ID for compound CPOs
getCPOAffect(compound)  # error: no affect for compound CPOs
```

#### Compound CPO decomposition, CPO chaining

```{r}
as.list(compound)
pipeCPO(as.list(compound))  # chainCPO: list CPO -> CPO
```

#### CPO - Learner attachment using `%>>%` or `attachCPO`

```{r}
lrn = makeLearner("classif.logreg")
(cpolrn = cpo %>>% lrn)  # the new learner has the CPO hyperparameters
attachCPO(compound, lrn)  # attaching compound CPO
```

```{r}
# CPO learner decomposition
getLearnerCPO(cpolrn)  # the CPO
getLearnerBare(cpolrn)  # the Learner
```

### Retrafo
CPOs perform data-dependent operation. However, when this operation becomes part of a machine-learning process, the operation on predict-data must depend only on the training data.

The `Retrafo` object represents the re-application of a trained CPO

```{r}
transformed = iris %>>% cpo
head(transformed)
(ret = retrafo(transformed))
```
```{r}
# General methods that work on retrafo
getCPOName(ret)
getHyperPars(ret)
getCPOClass(ret)  # CPO Class: CPO, CPOInverter, CPORetrafo, NULLCPO
getCPOOperatingType(ret)  # Operating on feature, target, both?
getCPOPredictType(ret)
getCPOTrainedCapability(ret)  # can this be used for retrafo and/or invert?
```
```{r}
# retrafos are stored as attributes
attributes(transformed)$retrafo
```

#### Retrafo Inspection
`Retrafo` objects can be inspected using `getCPOTrainedState`. The state contains the hyperparameters, the `control` object (CPO dependent data representing the data information needed to re-apply the operation), and information about the `Task` / `data.frame` layout used for training (column names, column types) in `data$shapeinfo.input` and `data$shapeinfo.output`.

The state can be manipulated and used to create new `Retrafo`s, using `makeCPOTrainedFromState`.

```{r}
(state = getCPOTrainedState(retrafo(iris %>>% cpoScale())))
state$control$center[1] = 1000  # will now subtract 1000 from the first column
new.retrafo = makeCPOTrainedFromState(cpoScale, state)
head(iris %>>% new.retrafo)
```

#### Application of Retrafo using `%>>%`, `applyCPO`, or `predict`

```{r}
head(iris) %>>% retrafo(transformed)
```
Should give the same as head(transformed), since the same data was used:
```{r, eval = FALSE}
# same:
applyCPO(retrafo(transformed), head(iris))
predict(retrafo(transformed), head(iris))
```

#### Retrafos are automatically chained when applying CPOs (!!!)
When executing `data %>>% CPO`, the result has an associated `Retrafo` object. When applying another `CPO`, the `Retrafo` will be the chained operation. This is to make `data %>>% CPO1 %>>% CPO2` the way one expects it to work.

```{r}
data = head(iris) %>>% cpoPca()
retrafo(data)
data2 = data %>>% cpoScale()
# retrafo(data2) is the same as retrafo(data %>>% pca %>>% scale)
retrafo(data2)
# to interrupt this chain, set retrafo to NULL
retrafo(data) = NULL
data2 = data %>>% cpoScale()
retrafo(data2)
```

#### Retrafo Composition, Decomposition, Chaining
Using `as.list` and `pipeCPO`, just like for `CPO`s.
```{r}
compound.retrafo = retrafo(head(iris) %>>% compound)
compound.retrafo
(retrafolist = as.list(compound.retrafo))
retrafolist[[1]] %>>% retrafolist[[2]]
pipeCPO(retrafolist)
```

### Inverter
Inverters represent the operation of inverting transformations done to prediction columns. They are not usually exposed outside of `Learner` objects, but can be retrieved when retransformed data is tagged using `tagInverse`.

Inverters are not yet fully implemented.

```{r, eval = FALSE}
# there is currently no example targetbound cpo
logtransform = makeCPOTargetOp("logtransform",
  properties.target = "regr", constant.invert = TRUE,
  cpo.train = NULL,
  cpo.train.invert = NULL,
  cpo.retrafo = {
    target[[1]] = log(target[[1]])
    target
  }, cpo.invert = { exp(target) })


log.retrafo = retrafo(bh.task %>>% logtransform())  # get a target-bound retrafo
getCPOKind(log.retrafo)  # logtransform is *stateless*, so it is a retrafo *and* an inverter
getCPOBound(log.retrafo)

inverter(bh.task %>>% log.retrafo)
```
```{r, eval = FALSE}
inverter(tagInvert(bh.task) %>>% log.retrafo)
```

Inverting is done with the `invert` function.

```{r, eval = FALSE}
log.bh = bh.task %>>% logtransform()
log.prediction = predict(train("regr.lm", log.bh), log.bh)
invert(retrafo(log.bh), log.prediction)  # not implemented :-/
invert(retrafo(log.bh), log.prediction$data["response"])  # not implemented :-/
```

## CPO Properties
CPOs contain information about the kind of data they can work with, and what kind of data they produce. `getCPOProperties` returns a list with the slots `handling`, `adding`, `needed`, `properties$adding`, indicating the kind of data a CPO can handle, the kind of data it needs the data receiver (e.g. attached learner) to have, and the properties it adds to a given learner. An example is a CPO that converts factors to numerics: The receiving learner needs to handle numerics, so `properties$needed = "numerics"`, but it *adds* the ability to handle factors (since they are converted), so `properties$adding = c("factors", "ordered")`. `properties$data` is only different from `properties$handling` if `affect.*` parameters are given. In that case, `properties$data` determines what properties the selected subset of columns must have.

```{r, error = TRUE}
getCPOProperties(cpoDummyEncode())
train("classif.geoDA", bc.task)  # gives an error
```
```{r}
train(cpoDummyEncode(reference.cat = TRUE) %>>% makeLearner("classif.geoDA"), bc.task)
getLearnerProperties("classif.geoDA")
getLearnerProperties(cpoDummyEncode(TRUE) %>>% makeLearner("classif.geoDA"))
```

## Special CPOs

### NULLCPO
`NULLCPO` is the neutral element of `%>>%`. It is returned by some functions when no other CPO or Retrafo is present.

```{r}
NULLCPO
is.nullcpo(NULLCPO)
NULLCPO %>>% cpoScale()
NULLCPO %>>% NULLCPO
print(as.list(NULLCPO))
pipeCPO(list())
```

### CPO Wrapper
A simple CPO with one parameter which gets applied to the data as CPO. This is different from a multiplexer in that its parameter is free and can take any value that behaves like a CPO. On the downside, this does not expose the argument's parameters to the outside.

```{r}
cpa = cpoWrap()
print(cpa, verbose = TRUE)
head(iris %>>% setHyperPars(cpa, wrap.cpo = cpoScale()))
head(iris %>>% setHyperPars(cpa, wrap.cpo = cpoPca()))
# attaching the cpo applicator to a learner gives this learner a "cpo" hyperparameter
# that can be set to any CPO.
getParamSet(cpoWrap() %>>% makeLearner("classif.logreg"))
```

### CPO Multiplexer
Combine many CPOs into one, with an extra `selected.cpo` parameter that chooses between them.

```{r}
cpm = cpoMultiplex(list(cpoScale, cpoPca))
print(cpm, verbose = TRUE)
head(iris %>>% setHyperPars(cpm, selected.cpo = "scale"))
# every CPO's Hyperparameters are exported
head(iris %>>% setHyperPars(cpm, selected.cpo = "scale", scale.center = FALSE))
head(iris %>>% setHyperPars(cpm, selected.cpo = "pca"))
```

### Case-CPO
A CPO that builds data-dependent CPO networks. This is a generalized CPO-Multiplexer that takes a function which decides (from the data, and from user-specified hyperparameters) what CPO operation to perform. Besides optional arguments, the used CPO's Hyperparameters are exported as well. This is a generalization of `cpoMultiplex`; however, `requires` of the involved parameters are not adjusted, since this is impossible in principle.

```{r}
s.and.p = cpoCase(pSS(logical.param: logical),
  export.cpos = list(cpoScale(), 
  cpoPca()),
  cpo.build = function(data, target, logical.param, scale, pca) {
  if (logical.param || mean(data[[1]]) > 10) {
    scale %>>% pca
  } else {
    pca %>>% scale
  }
  })
print(s.and.p, verbose = TRUE)
```

The resulting CPO `s.and.p` performs scaling and PCA, with the order depending on the parameter `logical.param` and on whether the mean of the data's first column exceeds 10. If either of those is true, the data will be first scaled, then PCA'd, otherwise the order is reversed.
The all CPOs listed in `.export` are passed to the `cpo.build`.

### CBind CPO
`cbind` other CPOs as operation. The `cbinder` makes it possible to build DAGs of CPOs that perform different operations on data and paste the results next to each other.

```{r}
scale = cpoScale(id = "scale")
scale.pca = scale %>>% cpoPca()
cbinder = cpoCbind(scaled = scale, pcad = scale.pca, original = NULLCPO)
```
```{r}
# cpoCbind recognises that "scale.scale" happens before "pca.pca" but is also fed to the
# result directly. The summary draws a (crude) ascii-art graph.
print(cbinder, verbose = TRUE)
head(iris %>>% cbinder)
```
```{r}
# the unnecessary copies of "Species" are unfortunate. Remove them with cpoSelect:
selector = cpoSelect(type = "numeric")
cbinder.select = cpoCbind(scaled = selector %>>% scale, pcad = selector %>>% scale.pca, original = NULLCPO)
cbinder.select
head(iris %>>% cbinder)
```
```{r}
# alternatively, we apply the cbinder only to numerical data
head(iris %>>% cpoWrap(cbinder, affect.type = "numeric"))
```

## Builtin CPOs

### Listing CPOs
Builtin CPOs can be listed with `listCPO()`.

```{r}
listCPO()$name
```

### cpoScale
Implements the `base::scale` function.

```{r}
df %>>% cpoScale()
df %>>% cpoScale(scale = FALSE)  # center = TRUE
```

### cpoPca
Implements `stats::prcomp`. No scaling or centering is performed.

```{r}
df %>>% cpoPca()
```

### cpoDummyEncode
Dummy encoding of factorial variables. Optionally uses the first factor as reference variable.

```{r}
head(iris %>>% cpoDummyEncode())
head(iris %>>% cpoDummyEncode(reference.cat = TRUE))
```

### cpoSelect
Select to use only certain columns of a dataset. Select by column index, name, or regex pattern.

```{r}
head(iris %>>% cpoSelect(pattern = "Width"))
# selection is additive
head(iris %>>% cpoSelect(pattern = "Width", type = "factor"))
```

### cpoDropConstants
Drops constant features or numerics, with variable tolerance

```{r}
head(iris) %>>% cpoDropConstants()  # drops 'species'
head(iris) %>>% cpoDropConstants(abs.tol = 0.2)  # also drops 'Petal.Width'
```

### cpoFixFactors
Drops unused factors and makes sure prediction data has the same factor levels as training data.

```{r}
levels(iris$Species)
```
```{r}
irisfix = head(iris) %>>% cpoFixFactors()  # Species only has level 'setosa' in train
levels(irisfix$Species)
```
```{r}
rf = retrafo(irisfix)
iris[c(1, 100, 140), ]
iris[c(1, 100, 140), ] %>>% rf
```

### cpoMissingIndicators
Creates columns indicating missing data. Most useful in combination with cpoCbind.

```{r}
impdata = df
impdata[[1]][1] = NA
impdata
```
```{r}
impdata %>>% cpoMissingIndicators()
impdata %>>% cpoCbind(NULLCPO, dummy = cpoMissingIndicators())
```

### cpoApplyFun
Apply an univariate function to data columns

```{r}
head(iris %>>% cpoApplyFun(function(x) sqrt(x) - 10, affect.type = "numeric"))
```

### cpoAsNumeric
Convert (non-numeric) features to numeric

```{r}
head(iris[sample(nrow(iris), 10), ] %>>% cpoAsNumeric())
```

### cpoCollapseFact
Combine low prevalence factors. Set `max.collapsed.class.prevalence` how big the combined factor level may be.

```{r}
iris2 = iris
iris2$Species = factor(c("a", "b", "c", "b", "b", "c", "b", "c",
                        as.character(iris2$Species[-(1:8)])))
head(iris2, 10)
head(iris2 %>>% cpoCollapseFact(max.collapsed.class.prevalence = 0.2), 10)
```

### cpoModelMatrix
Specify which columns get used, and how they are transformed, using a `formula`.

```{r}
head(iris %>>% cpoModelMatrix(~0 + Species:Petal.Width))
# use . + ... to retain originals
head(iris %>>% cpoModelMatrix(~0 + . + Species:Petal.Width))
```

### cpoScaleRange
scale values to a given range

```{r}
head(iris %>>% cpoScaleRange(-1, 1))
```

### cpoScaleMaxAbs
Multiply features to set the maximum absolute value.

```{r}
head(iris %>>% cpoScaleMaxAbs(0.1))
```

### cpoSpatialSign
Normalize values row-wise

```{r}
head(iris %>>% cpoSpatialSign())
```

### Imputation
There are two *general* and many *specialised* imputation CPOs. The general imputation CPOs have parameters that let them use different imputation methods on different columns. They are a thin wrapper around `mlr`'s `impute()` and `reimpute()` functions. The specialised imputation CPOs each implement exactly one imputation method and are closer to the behaviour of typical CPOs.

#### General Imputation Wrappers
`cpoImpute` and `cpoImputeAll` both have parameters very much like `impute()`. The latter assumes that *all* columns of its input is somehow being imputed and can be preprended to a learner to give it the ability to work with missing data. It will, however, throw an error if data is missing after imputation.

```{r}
impdata %>>% cpoImpute(cols = list(a = imputeMedian()))
```
```{r, error = TRUE}
impdata %>>% cpoImpute(cols = list(b = imputeMedian()))  # NAs remain
impdata %>>% cpoImputeAll(cols = list(b = imputeMedian()))  # error, since NAs remain
```

```{r, error = TRUE}
missing.task = makeRegrTask("missing.task", impdata, target = "b")
# the following gives an error, since 'cpoImpute' does not make sure all missings are removed
# and hence does not add the 'missings' property.
train(cpoImpute(cols = list(a = imputeMedian())) %>>% makeLearner("regr.lm"), missing.task)
```
```{r}
# instead, the following works:
train(cpoImputeAll(cols = list(a = imputeMedian())) %>>% makeLearner("regr.lm"), missing.task)
```

#### Specialised Imputation Wrappers
There is one for each imputation method.

```{r}
impdata %>>% cpoImputeConstant(10)
getTaskData(missing.task %>>% cpoImputeMedian())
# The specialised impute CPOs are:
listCPO()[listCPO()$category == "imputation" & listCPO()$subcategory == "specialised",
          c("name", "description")]
```

### Feature Filtering
There is one *general* and many *specialised* feature filtering CPOs. The general filtering CPO, `cpoFilterFeatures`, is a thin wrapper around `filterFeatures` and takes the filtering method as its argument. The specialised CPOs each call a specific filtering method.

Most arguments of `filterFeatures` are reflected in the CPOs. The exceptions being:
1. for `filterFeatures`, the filter method arguments are given in a list `filter.args`, instead of in `...`
2. The argument `fval` was dropped for the specialised filter CPOs.
3. The argument `mandatory.feat` was dropped. Use `affect.*` parameters to prevent features from being filtered.

```{r}
head(getTaskData(iris.task %>>% cpoFilterFeatures(method = "variance", perc = 0.5)))
head(getTaskData(iris.task %>>% cpoFilterVariance(perc = 0.5)))
# The specialised filter CPOs are:
listCPO()[listCPO()$category == "featurefilter" & listCPO()$subcategory == "specialised",
          c("name", "description")]
```

## Creating Custom CPOs
Custom CPOs can be created using the `makeCPO` function. Its most important arguments are `cpo.trafo` and `cpo.retrafo`, both of which are functions. The `cpo.trafo`-function must return a "control" object which contains all information about how to transform a given dataset. `cpo.retrafo` takes a (potentially new!) dataset *and* the "control" object returned by `cpo.trafo`, and transforms the new data according to plan.
```{r}
names(formals(makeCPO))  # see help(makeCPO) for explanation of arguments
```

```{r}
constFeatRem = makeCPO("constFeatRem",
  dataformat = "df.features",
  cpo.train = function(data, target) {
    names(Filter(function(x) {  # names of columns to keep
        length(unique(x)) > 1
      }, data))
    }, cpo.retrafo = function(data, control) {
    data[control]
  })
head(iris) %>>% constFeatRem()
print(constFeatRem, verbose = TRUE)
```

It is also possible to set `cpo.retrafo = NULL`. Then `cpo.trafo` must return a function that takes a `data` argument, which is a (possibly new) dataset to transform, and returns the transformed data. The following example is equivalent to the example above:
```{r}
constFeatRem = makeCPO("constFeatRem",
  dataformat = "df.features",
  cpo.train = function(data, target) {
    cols.keep = names(Filter(function(x) {
    length(unique(x)) > 1
      }, data))
    # the following function will do both the trafo and retrafo
    result = function(data) {
      data[cols.keep]
    }
    result
  }, cpo.retrafo = NULL)
head(iris) %>>% constFeatRem()
print(constFeatRem, verbose = TRUE)
```

## Tuning CPO
CPOs export their parameters when attached to a learner. Tuning of CPO-Learners works exactly as tuning for ordinary Learners.

```{r}
(clrn = cpoModelMatrix() %>>% makeLearner("classif.logreg"))
getParamSet(clrn)

ps = makeParamSet(
    makeDiscreteParam(
        "model.matrix.formula",
        values = list(first = ~0 + ., second = ~0 + .^2, third = ~0 + .^3)))

tuneParams(clrn, pid.task, cv5, par.set = ps,
           control = makeTuneControlGrid(),
           show.info=TRUE)
```
Tuning of CPOs and tuning of Learners can happen at the same time. The following is not executed to save build time.
```{r, eval = FALSE}
tlrn = cpoModelMatrix() %>>%
       cpoWrap() %>>%
       cpoFilterGainRatio() %>>%
       makeLearner("classif.ctree")
sprintf("Parameters: %s", paste(names(getParamSet(tlrn)$pars), collapse=", "))
ps2 = makeParamSet(
    makeDiscreteParam(
        "model.matrix.formula",
        values = list(first = ~0 + ., second = ~0 + .^2)),
    makeDiscreteParam(
        "wrap.cpo",
        values = list(nopca = NULLCPO,
                      onlypca = cpoPca(),
                      addpca = cpoCbind(NULLCPO, cpoPca()))),
    makeDiscreteParam(
        "gain.ratio.perc",
        values = list(0.333, 0.667, 1.0)),
    makeDiscreteParam("teststat", values = c("quad", "max")))

tuneParams(tlrn, pid.task, cv5, par.set = ps2,
           control = makeTuneControlGrid())
```
